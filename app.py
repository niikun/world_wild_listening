# app_langchain.py - World Listening & Wild Listening (LangChainç‰ˆ)

import gradio as gr
import pandas as pd
import numpy as np
import plotly.express as px
import plotly.graph_objects as go
from plotly.subplots import make_subplots
import random
import json
import asyncio
import time
import os
from datetime import datetime
from dataclasses import dataclass, asdict
from typing import Dict, List, Any, Tuple, Optional

# LangChain imports
try:
    from langchain_openai import ChatOpenAI
    from langchain_anthropic import ChatAnthropic
    from langchain_google_genai import ChatGoogleGenerativeAI
    from langchain_community.llms import Ollama
    from langchain_core.prompts import ChatPromptTemplate, SystemMessagePromptTemplate, HumanMessagePromptTemplate
    from langchain_core.output_parsers import StrOutputParser
    from langchain_core.runnables import RunnablePassthrough, RunnableParallel
    from langchain.schema import BaseMessage, HumanMessage, SystemMessage
    from langchain.callbacks import get_openai_callback
    LANGCHAIN_AVAILABLE = True
except ImportError:
    LANGCHAIN_AVAILABLE = False
    print("LangChainãƒ©ã‚¤ãƒ–ãƒ©ãƒªãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚pip install langchain langchain-openai langchain-anthropic langchain-google-genaiã‚’å®Ÿè¡Œã—ã¦ãã ã•ã„ã€‚")

@dataclass
class HumanPersona:
    """äººé–“ãƒšãƒ«ã‚½ãƒŠãƒ—ãƒ­ãƒ•ã‚¡ã‚¤ãƒ«"""
    id: int
    age: int
    gender: str
    country: str
    occupation: str
    education: str
    income_level: str
    family_status: str
    language: str
    urban_rural: str
    continent: str

@dataclass
class AnimalPersona:
    """å‹•ç‰©ãƒšãƒ«ã‚½ãƒŠãƒ—ãƒ­ãƒ•ã‚¡ã‚¤ãƒ«"""
    id: int
    species: str
    habitat: str
    size_category: str
    diet_type: str
    activity_pattern: str
    social_structure: str
    lifespan_category: str
    conservation_status: str
    continent: str

class WorldDemographicsDB:
    """ä¸–ç•Œäººå£å‹•æ…‹ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹"""
    
    def __init__(self):
        self.setup_world_demographics()
    
    def setup_world_demographics(self):
        """ä¸–ç•Œäººå£å‹•æ…‹ãƒ‡ãƒ¼ã‚¿ã®åˆæœŸåŒ–"""
        
        # å¹´é½¢åˆ†å¸ƒï¼ˆä¸–ç•Œå¹³å‡ï¼‰
        self.age_distribution = {
            (0, 14): 25.4, (15, 24): 15.5, (25, 34): 17.2, (35, 44): 13.8,
            (45, 54): 11.9, (55, 64): 8.7, (65, 74): 5.2, (75, 100): 2.3
        }
        
        # å›½åˆ¥äººå£åˆ†å¸ƒï¼ˆäººå£ä¸Šä½å›½ï¼‹ãã®ä»–ï¼‰
        self.country_distribution = {
            'ä¸­å›½': 17.8, 'ã‚¤ãƒ³ãƒ‰': 17.7, 'ã‚¢ãƒ¡ãƒªã‚«': 4.2, 'ã‚¤ãƒ³ãƒ‰ãƒã‚·ã‚¢': 3.4,
            'ãƒ‘ã‚­ã‚¹ã‚¿ãƒ³': 2.8, 'ãƒ–ãƒ©ã‚¸ãƒ«': 2.7, 'ãƒŠã‚¤ã‚¸ã‚§ãƒªã‚¢': 2.6, 'ãƒãƒ³ã‚°ãƒ©ãƒ‡ã‚·ãƒ¥': 2.1,
            'ãƒ­ã‚·ã‚¢': 1.9, 'ãƒ¡ã‚­ã‚·ã‚³': 1.6, 'æ—¥æœ¬': 1.6, 'ãƒ•ã‚£ãƒªãƒ”ãƒ³': 1.4,
            'ã‚¨ãƒã‚ªãƒ”ã‚¢': 1.4, 'ãƒ™ãƒˆãƒŠãƒ ': 1.2, 'ã‚¨ã‚¸ãƒ—ãƒˆ': 1.3, 'ãƒˆãƒ«ã‚³': 1.1,
            'ã‚¤ãƒ©ãƒ³': 1.1, 'ãƒ‰ã‚¤ãƒ„': 1.1, 'ã‚¿ã‚¤': 0.9, 'ã‚¤ã‚®ãƒªã‚¹': 0.9,
            'ãã®ä»–': 32.8
        }
        
        # ä¸»è¦è¨€èªåˆ†å¸ƒ
        self.language_distribution = {
            'ä¸­å›½èªï¼ˆæ¨™æº–ï¼‰': 14.1, 'ãƒ’ãƒ³ãƒ‡ã‚£ãƒ¼èª': 6.0, 'è‹±èª': 5.1, 'ã‚¹ãƒšã‚¤ãƒ³èª': 4.9,
            'ã‚¢ãƒ©ãƒ“ã‚¢èª': 4.2, 'ãƒ™ãƒ³ã‚¬ãƒ«èª': 3.3, 'ãƒãƒ«ãƒˆã‚¬ãƒ«èª': 2.9, 'ãƒ­ã‚·ã‚¢èª': 2.2,
            'æ—¥æœ¬èª': 1.7, 'ãƒ•ãƒ©ãƒ³ã‚¹èª': 1.3, 'ãƒ‰ã‚¤ãƒ„èª': 1.0, 'éŸ“å›½èª': 0.9,
            'ãƒ™ãƒˆãƒŠãƒ èª': 0.9, 'ãƒˆãƒ«ã‚³èª': 0.8, 'ã‚¤ã‚¿ãƒªã‚¢èª': 0.7, 'ãã®ä»–': 50.0
        }
        
        # ä¸–ç•Œè·æ¥­åˆ†å¸ƒ
        self.occupation_distribution = {
            'è¾²æ¥­ãƒ»ç•œç”£æ¥­': 26.2, 'ã‚µãƒ¼ãƒ“ã‚¹æ¥­': 15.8, 'è£½é€ æ¥­': 12.6,
            'å•†æ¥­ãƒ»è²¿æ˜“': 11.0, 'å»ºè¨­æ¥­': 6.9, 'æ•™è‚²é–¢ä¿‚': 4.7,
            'åŒ»ç™‚ãƒ»ä»‹è­·': 4.2, 'å…¬å‹™å“¡': 3.8, 'ITãƒ»æŠ€è¡“': 2.9,
            'é‹è¼¸æ¥­': 2.8, 'é‡‘èæ¥­': 2.1, 'å­¦ç”Ÿ': 4.5, 'ç„¡è·': 2.5
        }
        
        # æ•™è‚²ãƒ¬ãƒ™ãƒ«
        self.education_distribution = {
            'ç„¡å­¦æ­´': 13.2, 'åˆç­‰æ•™è‚²': 28.4, 'ä¸­ç­‰æ•™è‚²': 35.7,
            'è·æ¥­è¨“ç·´': 8.9, 'é«˜ç­‰æ•™è‚²': 11.2, 'å¤§å­¦é™¢': 2.6
        }
        
        # å¹´ååˆ†å¸ƒï¼ˆUSDï¼‰
        self.income_distribution = {
            '1,000ãƒ‰ãƒ«æœªæº€': 15.3, '1,000-5,000ãƒ‰ãƒ«': 28.7, '5,000-15,000ãƒ‰ãƒ«': 26.9,
            '15,000-30,000ãƒ‰ãƒ«': 14.2, '30,000-50,000ãƒ‰ãƒ«': 7.8, '50,000-75,000ãƒ‰ãƒ«': 4.1,
            '75,000-100,000ãƒ‰ãƒ«': 1.8, '100,000ãƒ‰ãƒ«ä»¥ä¸Š': 1.2
        }
        
        # å®¶æ—æ§‹æˆ
        self.family_status_distribution = {
            'ç‹¬èº«': 22.8, 'æ—¢å©š': 45.3, 'æ—¢å©šãƒ»å­ä¾›ã‚ã‚Š': 25.5,
            'ã²ã¨ã‚Šè¦ª': 4.2, 'å¤§å®¶æ—': 2.2
        }

class TerrestrialAnimalDB:
    """é™¸ä¸Šå‹•ç‰©ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹"""
    
    def __init__(self):
        self.setup_animal_demographics()
    
    def setup_animal_demographics(self):
        """å‹•ç‰©ãƒ‡ãƒ¼ã‚¿ã®åˆæœŸåŒ–"""
        
        # ç¨®åˆ¥åˆ†å¸ƒï¼ˆä¸»è¦é™¸ä¸Šå‹•ç‰©ï¼‰
        self.species_distribution = {
            'ã‚¢ãƒ•ãƒªã‚«ã‚¾ã‚¦': 2.1, 'ãƒ©ã‚¤ã‚ªãƒ³': 1.8, 'ãƒˆãƒ©': 0.8, 'ãƒ’ã‚°ãƒ': 2.3,
            'ã‚ªã‚ªã‚«ãƒŸ': 3.2, 'ã‚¢ã‚«ã‚®ãƒ„ãƒ': 4.5, 'ã‚·ã‚«': 5.8, 'ã‚¤ãƒã‚·ã‚·': 3.9,
            'ãƒãƒ³ãƒ‘ãƒ³ã‚¸ãƒ¼': 1.2, 'ã‚´ãƒªãƒ©': 0.6, 'ã‚ªãƒ©ãƒ³ã‚¦ãƒ¼ã‚¿ãƒ³': 0.4, 'ãƒ’ãƒ§ã‚¦': 1.5,
            'ãƒãƒ¼ã‚¿ãƒ¼': 0.3, 'ã‚­ãƒªãƒ³': 1.1, 'ã‚·ãƒã‚¦ãƒ': 2.7, 'ã‚µã‚¤': 0.5,
            'ã‚«ãƒ': 1.3, 'ã‚«ãƒ³ã‚¬ãƒ«ãƒ¼': 3.4, 'ãƒ‘ãƒ³ãƒ€': 0.2, 'ãƒ¦ã‚­ãƒ’ãƒ§ã‚¦': 0.3,
            'ã‚¸ãƒ£ã‚¬ãƒ¼': 0.7, 'ãƒ”ãƒ¥ãƒ¼ãƒ': 1.9, 'ã‚ªã‚ªãƒ¤ãƒãƒã‚³': 1.4, 'ãƒã‚¤ã‚½ãƒ³': 1.6,
            'ãƒ˜ãƒ©ã‚¸ã‚«': 2.1, 'ãƒˆãƒŠã‚«ã‚¤': 3.8, 'ãƒ¤ãƒãƒ¤ã‚®': 1.7, 'ãã®ä»–': 53.5
        }
        
        # ç”Ÿæ¯ç’°å¢ƒ
        self.habitat_distribution = {
            'ç†±å¸¯é›¨æ—': 18.2, 'æ¸©å¸¯æ—': 15.4, 'è‰åŸãƒ»ã‚µãƒãƒ³ãƒŠ': 22.1,
            'ç ‚æ¼ ': 8.7, 'å±±å²³åœ°å¸¯': 12.3, 'ãƒ„ãƒ³ãƒ‰ãƒ©': 6.8, 'æ¹¿åœ°': 7.2,
            'æ²¿å²¸éƒ¨': 4.1, 'æ··åˆç’°å¢ƒ': 5.2
        }
        
        # ã‚µã‚¤ã‚ºã‚«ãƒ†ã‚´ãƒª
        self.size_distribution = {
            'æ¥µå°ï¼ˆ1kgæœªæº€ï¼‰': 8.2, 'å°å‹ï¼ˆ1-10kgï¼‰': 25.4, 'ä¸­å‹ï¼ˆ10-50kgï¼‰': 28.7,
            'å¤§å‹ï¼ˆ50-200kgï¼‰': 22.1, 'è¶…å¤§å‹ï¼ˆ200-1000kgï¼‰': 12.8, 'å·¨å¤§ï¼ˆ1000kgä»¥ä¸Šï¼‰': 2.8
        }
        
        # é£Ÿæ€§
        self.diet_distribution = {
            'è‰é£Ÿå‹•ç‰©': 42.3, 'è‚‰é£Ÿå‹•ç‰©': 18.7, 'é›‘é£Ÿå‹•ç‰©': 28.4, 'æ˜†è™«é£Ÿ': 10.6
        }
        
        # æ´»å‹•ãƒ‘ã‚¿ãƒ¼ãƒ³
        self.activity_distribution = {
            'æ˜¼è¡Œæ€§': 45.2, 'å¤œè¡Œæ€§': 32.1, 'è–„æ˜æ´»å‹•': 15.7, 'ç„¡æ—¥å‘¨æ€§': 7.0
        }
        
        # ç¤¾ä¼šæ§‹é€ 
        self.social_distribution = {
            'å˜ç‹¬è¡Œå‹•': 38.4, 'ã¤ãŒã„': 12.6, 'å°ã‚°ãƒ«ãƒ¼ãƒ—': 23.8, 'å¤§ç¾¤': 18.2, 'è¤‡é›‘ãªç¤¾ä¼š': 7.0
        }
        
        # å¯¿å‘½ã‚«ãƒ†ã‚´ãƒª
        self.lifespan_distribution = {
            'çŸ­å‘½ï¼ˆ1-5å¹´ï¼‰': 15.2, 'æ™®é€šï¼ˆ5-15å¹´ï¼‰': 35.8, 'é•·å¯¿ï¼ˆ15-30å¹´ï¼‰': 28.4,
            'éå¸¸ã«é•·å¯¿ï¼ˆ30-50å¹´ï¼‰': 15.3, 'è¶…é•·å¯¿ï¼ˆ50å¹´ä»¥ä¸Šï¼‰': 5.3
        }
        
        # ä¿è­·çŠ¶æ³
        self.conservation_distribution = {
            'è»½åº¦æ‡¸å¿µ': 45.2, 'æº–çµ¶æ»…å±æƒ§': 18.7, 'å±æ€¥': 15.8,
            'çµ¶æ»…å±æƒ§': 12.3, 'æ·±åˆ»ãªå±æ©Ÿ': 8.0
        }

class PersonaGenerator:
    """äººé–“ãƒ»å‹•ç‰©ä¸¡å¯¾å¿œãƒšãƒ«ã‚½ãƒŠç”Ÿæˆå™¨"""
    
    def __init__(self, mode: str):
        self.mode = mode
        if mode == "humans":
            self.db = WorldDemographicsDB()
        else:  # animals
            self.db = TerrestrialAnimalDB()
    
    def generate_weighted_choice(self, distribution: Dict[str, float]) -> str:
        """é‡ã¿ä»˜ãç¢ºç‡é¸æŠ"""
        choices = list(distribution.keys())
        weights = list(distribution.values())
        return random.choices(choices, weights=weights)[0]
    
    def get_continent_from_country(self, country: str) -> str:
        """å›½ã‹ã‚‰å¤§é™¸ã‚’å–å¾—"""
        continent_map = {
            'ä¸­å›½': 'ã‚¢ã‚¸ã‚¢', 'ã‚¤ãƒ³ãƒ‰': 'ã‚¢ã‚¸ã‚¢', 'ã‚¢ãƒ¡ãƒªã‚«': 'åŒ—ç±³',
            'ã‚¤ãƒ³ãƒ‰ãƒã‚·ã‚¢': 'ã‚¢ã‚¸ã‚¢', 'ãƒ‘ã‚­ã‚¹ã‚¿ãƒ³': 'ã‚¢ã‚¸ã‚¢', 'ãƒ–ãƒ©ã‚¸ãƒ«': 'å—ç±³',
            'ãƒŠã‚¤ã‚¸ã‚§ãƒªã‚¢': 'ã‚¢ãƒ•ãƒªã‚«', 'ãƒãƒ³ã‚°ãƒ©ãƒ‡ã‚·ãƒ¥': 'ã‚¢ã‚¸ã‚¢', 'ãƒ­ã‚·ã‚¢': 'ãƒ¨ãƒ¼ãƒ­ãƒƒãƒ‘ãƒ»ã‚¢ã‚¸ã‚¢',
            'ãƒ¡ã‚­ã‚·ã‚³': 'åŒ—ç±³', 'æ—¥æœ¬': 'ã‚¢ã‚¸ã‚¢', 'ãƒ•ã‚£ãƒªãƒ”ãƒ³': 'ã‚¢ã‚¸ã‚¢',
            'ã‚¨ãƒã‚ªãƒ”ã‚¢': 'ã‚¢ãƒ•ãƒªã‚«', 'ãƒ™ãƒˆãƒŠãƒ ': 'ã‚¢ã‚¸ã‚¢', 'ã‚¨ã‚¸ãƒ—ãƒˆ': 'ã‚¢ãƒ•ãƒªã‚«',
            'ãƒˆãƒ«ã‚³': 'ãƒ¨ãƒ¼ãƒ­ãƒƒãƒ‘ãƒ»ã‚¢ã‚¸ã‚¢', 'ã‚¤ãƒ©ãƒ³': 'ã‚¢ã‚¸ã‚¢', 'ãƒ‰ã‚¤ãƒ„': 'ãƒ¨ãƒ¼ãƒ­ãƒƒãƒ‘',
            'ã‚¿ã‚¤': 'ã‚¢ã‚¸ã‚¢', 'ã‚¤ã‚®ãƒªã‚¹': 'ãƒ¨ãƒ¼ãƒ­ãƒƒãƒ‘'
        }
        return continent_map.get(country, 'ä¸–ç•Œå„åœ°')
    
    def get_continent_from_habitat(self, habitat: str) -> str:
        """ç”Ÿæ¯ç’°å¢ƒã‹ã‚‰å¤§é™¸ã‚’æ¨å®š"""
        habitat_continent_map = {
            'ç†±å¸¯é›¨æ—': 'ã‚¢ãƒ•ãƒªã‚«ãƒ»å—ç±³ãƒ»ã‚¢ã‚¸ã‚¢',
            'æ¸©å¸¯æ—': 'åŒ—ç±³ãƒ»ãƒ¨ãƒ¼ãƒ­ãƒƒãƒ‘',
            'è‰åŸãƒ»ã‚µãƒãƒ³ãƒŠ': 'ã‚¢ãƒ•ãƒªã‚«ãƒ»ã‚¢ã‚¸ã‚¢',
            'ç ‚æ¼ ': 'ã‚¢ãƒ•ãƒªã‚«ãƒ»ã‚¢ã‚¸ã‚¢ãƒ»ã‚ªãƒ¼ã‚¹ãƒˆãƒ©ãƒªã‚¢',
            'å±±å²³åœ°å¸¯': 'ä¸–ç•Œå„åœ°',
            'ãƒ„ãƒ³ãƒ‰ãƒ©': 'åŒ—ç±³ãƒ»ãƒ¨ãƒ¼ãƒ­ãƒƒãƒ‘ãƒ»ã‚¢ã‚¸ã‚¢',
            'æ¹¿åœ°': 'ä¸–ç•Œå„åœ°',
            'æ²¿å²¸éƒ¨': 'ä¸–ç•Œå„åœ°',
            'æ··åˆç’°å¢ƒ': 'ä¸–ç•Œå„åœ°'
        }
        return habitat_continent_map.get(habitat, 'ä¸–ç•Œå„åœ°')
    
    def generate_human_persona(self, persona_id: int) -> HumanPersona:
        """äººé–“ãƒšãƒ«ã‚½ãƒŠç”Ÿæˆ"""
        # å¹´é½¢ç”Ÿæˆ
        age_ranges = list(self.db.age_distribution.keys())
        age_weights = list(self.db.age_distribution.values())
        selected_range = random.choices(age_ranges, weights=age_weights)[0]
        age = random.randint(selected_range[0], selected_range[1])
        
        # åŸºæœ¬å±æ€§
        country = self.generate_weighted_choice(self.db.country_distribution)
        
        persona = HumanPersona(
            id=persona_id,
            age=age,
            gender=random.choice(['ç”·æ€§', 'å¥³æ€§']),
            country=country,
            occupation=self.generate_weighted_choice(self.db.occupation_distribution),
            education=self.generate_weighted_choice(self.db.education_distribution),
            income_level=self.generate_weighted_choice(self.db.income_distribution),
            family_status=self.generate_weighted_choice(self.db.family_status_distribution),
            language=self.generate_weighted_choice(self.db.language_distribution),
            urban_rural=random.choice(['éƒ½å¸‚éƒ¨', 'åœ°æ–¹']),
            continent=self.get_continent_from_country(country)
        )
        
        return persona
    
    def generate_animal_persona(self, persona_id: int) -> AnimalPersona:
        """å‹•ç‰©ãƒšãƒ«ã‚½ãƒŠç”Ÿæˆ"""
        habitat = self.generate_weighted_choice(self.db.habitat_distribution)
        
        persona = AnimalPersona(
            id=persona_id,
            species=self.generate_weighted_choice(self.db.species_distribution),
            habitat=habitat,
            size_category=self.generate_weighted_choice(self.db.size_distribution),
            diet_type=self.generate_weighted_choice(self.db.diet_distribution),
            activity_pattern=self.generate_weighted_choice(self.db.activity_distribution),
            social_structure=self.generate_weighted_choice(self.db.social_distribution),
            lifespan_category=self.generate_weighted_choice(self.db.lifespan_distribution),
            conservation_status=self.generate_weighted_choice(self.db.conservation_distribution),
            continent=self.get_continent_from_habitat(habitat)
        )
        
        return persona
    
    def generate_persona(self, persona_id: int):
        """ãƒ¢ãƒ¼ãƒ‰ã«å¿œã˜ãŸãƒšãƒ«ã‚½ãƒŠç”Ÿæˆ"""
        if self.mode == "humans":
            return self.generate_human_persona(persona_id)
        else:
            return self.generate_animal_persona(persona_id)

class LangChainCostTracker:
    """LangChainç”¨ã‚³ã‚¹ãƒˆè¿½è·¡ã‚¯ãƒ©ã‚¹"""
    
    def __init__(self):
        self.total_cost = 0.0
        self.total_tokens = 0
        self.requests_count = 0
        self.provider_costs = {}
        
    def add_openai_callback_result(self, result):
        """OpenAIã‚³ãƒ¼ãƒ«ãƒãƒƒã‚¯çµæœã‚’è¿½åŠ """
        self.total_cost += result.total_cost
        self.total_tokens += result.total_tokens
        self.requests_count += 1
        
        if 'openai' not in self.provider_costs:
            self.provider_costs['openai'] = {'cost': 0, 'tokens': 0, 'requests': 0}
        
        self.provider_costs['openai']['cost'] += result.total_cost
        self.provider_costs['openai']['tokens'] += result.total_tokens
        self.provider_costs['openai']['requests'] += 1
    
    def add_manual_cost(self, cost: float, tokens: int, provider: str):
        """æ‰‹å‹•ã§ã‚³ã‚¹ãƒˆã‚’è¿½åŠ ï¼ˆä»–ã®ãƒ—ãƒ­ãƒã‚¤ãƒ€ãƒ¼ç”¨ï¼‰"""
        self.total_cost += cost
        self.total_tokens += tokens
        self.requests_count += 1
        
        if provider not in self.provider_costs:
            self.provider_costs[provider] = {'cost': 0, 'tokens': 0, 'requests': 0}
        
        self.provider_costs[provider]['cost'] += cost
        self.provider_costs[provider]['tokens'] += tokens
        self.provider_costs[provider]['requests'] += 1
    
    def get_cost_summary(self) -> Dict:
        """ã‚³ã‚¹ãƒˆã‚µãƒãƒªãƒ¼å–å¾—"""
        return {
            'total_cost_usd': self.total_cost,
            'total_cost_jpy': self.total_cost * 150,
            'total_tokens': self.total_tokens,
            'requests_count': self.requests_count,
            'cost_per_request': self.total_cost / max(self.requests_count, 1),
            'provider_breakdown': self.provider_costs
        }

class LangChainLLMProvider:
    """LangChainç”¨LLMãƒ—ãƒ­ãƒã‚¤ãƒ€ãƒ¼"""
    
    def __init__(self, provider_type: str, api_key: str, model_name: str = None):
        if not LANGCHAIN_AVAILABLE:
            raise ImportError("LangChainãƒ©ã‚¤ãƒ–ãƒ©ãƒªãŒå¿…è¦ã§ã™")
        
        self.provider_type = provider_type
        self.cost_tracker = LangChainCostTracker()
        
        # ãƒ—ãƒ­ãƒã‚¤ãƒ€ãƒ¼åˆ¥ã®LLMåˆæœŸåŒ–
        if provider_type == "openai":
            self.llm = ChatOpenAI(
                api_key=api_key,
                model=model_name or "gpt-4o-mini",
                temperature=0.7,
                max_tokens=150
            )
        elif provider_type == "anthropic":
            self.llm = ChatAnthropic(
                api_key=api_key,
                model=model_name or "claude-3-haiku-20240307",
                temperature=0.7,
                max_tokens=150
            )
        elif provider_type == "google":
            self.llm = ChatGoogleGenerativeAI(
                api_key=api_key,
                model=model_name or "gemini-pro",
                temperature=0.7
            )
        elif provider_type == "ollama":
            self.llm = Ollama(
                model=model_name or "llama2",
                temperature=0.7
            )
        else:
            raise ValueError(f"ã‚µãƒãƒ¼ãƒˆã•ã‚Œã¦ã„ãªã„ãƒ—ãƒ­ãƒã‚¤ãƒ€ãƒ¼: {provider_type}")
        
        # ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆã®è¨­å®š
        self.setup_prompt_templates()
        
        # ãƒã‚§ãƒ¼ãƒ³ã®ä½œæˆ
        self.setup_chains()
    
    def setup_prompt_templates(self):
        """ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆã®è¨­å®š"""
        
        # äººé–“ç”¨ã‚·ã‚¹ãƒ†ãƒ ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ
        self.human_system_template = SystemMessagePromptTemplate.from_template(
            """ã‚ãªãŸã¯{country}å‡ºèº«ã®{age}æ­³ã®{gender}ã§ã™ã€‚
ã‚ãªãŸã®èƒŒæ™¯æƒ…å ±:
- è·æ¥­: {occupation}
- æ•™è‚²: {education}
- è¨€èª: {language}
- å®¶æ—æ§‹æˆ: {family_status}
- ä½ç’°å¢ƒ: {urban_rural}

ã‚ãªãŸã®æ–‡åŒ–çš„èƒŒæ™¯ã€ä¾¡å€¤è¦³ã€ç”Ÿæ´»çµŒé¨“ã‚’è€ƒæ…®ã—ã¦ã€è³ªå•ã«è‡ªç„¶ã«å›ç­”ã—ã¦ãã ã•ã„ã€‚
150æ–‡å­—ä»¥å†…ã§ã€ã“ã®äººç‰©ã‚‰ã—ã„å£°ã§ç­”ãˆã¦ãã ã•ã„ã€‚"""
        )
        
        # å‹•ç‰©ç”¨ã‚·ã‚¹ãƒ†ãƒ ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ
        self.animal_system_template = SystemMessagePromptTemplate.from_template(
            """ã‚ãªãŸã¯{habitat}ã«ä½ã‚€{species}ã§ã™ã€‚
ã‚ãªãŸã®ç‰¹å¾´:
- ã‚µã‚¤ã‚º: {size_category}
- é£Ÿæ€§: {diet_type}
- æ´»å‹•ãƒ‘ã‚¿ãƒ¼ãƒ³: {activity_pattern}
- ç¤¾ä¼šæ§‹é€ : {social_structure}
- ä¿è­·çŠ¶æ³: {conservation_status}

ã“ã®å‹•ç‰©ã®æœ¬èƒ½ã€ç”Ÿæ…‹ã€ç’°å¢ƒã¨ã®é–¢ä¿‚ã‚’è€ƒæ…®ã—ã¦ã€è³ªå•ã«å¯¾ã™ã‚‹ã“ã®ç¨®ãªã‚‰ã§ã¯ã®åå¿œã‚’ç¤ºã—ã¦ãã ã•ã„ã€‚
150æ–‡å­—ä»¥å†…ã§ã€ã“ã®å‹•ç‰©ã®è¦–ç‚¹ã‹ã‚‰ç­”ãˆã¦ãã ã•ã„ã€‚"""
        )
        
        # äººé–“ç”¨ãƒãƒ£ãƒƒãƒˆãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ
        self.human_chat_template = ChatPromptTemplate.from_messages([
            self.human_system_template,
            HumanMessagePromptTemplate.from_template("{question}")
        ])
        
        # å‹•ç‰©ç”¨ãƒãƒ£ãƒƒãƒˆãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ
        self.animal_chat_template = ChatPromptTemplate.from_messages([
            self.animal_system_template,
            HumanMessagePromptTemplate.from_template("{question}")
        ])
    
    def setup_chains(self):
        """ãƒã‚§ãƒ¼ãƒ³ã®è¨­å®š"""
        
        # å‡ºåŠ›ãƒ‘ãƒ¼ã‚µãƒ¼
        self.output_parser = StrOutputParser()
        
        # äººé–“ç”¨ãƒã‚§ãƒ¼ãƒ³
        self.human_chain = self.human_chat_template | self.llm | self.output_parser
        
        # å‹•ç‰©ç”¨ãƒã‚§ãƒ¼ãƒ³
        self.animal_chain = self.animal_chat_template | self.llm | self.output_parser
    
    async def generate_response(self, persona: Dict, question: str, mode: str) -> Dict:
        """LangChainã‚’ä½¿ç”¨ã—ãŸå›ç­”ç”Ÿæˆ"""
        
        try:
            # ãƒã‚§ãƒ¼ãƒ³ã®é¸æŠ
            if mode == "humans":
                chain = self.human_chain
                chain_input = {
                    "age": persona["age"],
                    "gender": persona["gender"],
                    "country": persona["country"],
                    "occupation": persona["occupation"],
                    "education": persona["education"],
                    "language": persona["language"],
                    "family_status": persona["family_status"],
                    "urban_rural": persona["urban_rural"],
                    "question": question
                }
            else:
                chain = self.animal_chain
                chain_input = {
                    "species": persona["species"],
                    "habitat": persona["habitat"],
                    "size_category": persona["size_category"],
                    "diet_type": persona["diet_type"],
                    "activity_pattern": persona["activity_pattern"],
                    "social_structure": persona["social_structure"],
                    "conservation_status": persona["conservation_status"],
                    "question": question
                }
            
            # OpenAIã®å ´åˆã¯ã‚³ã‚¹ãƒˆãƒˆãƒ©ãƒƒã‚­ãƒ³ã‚°
            if self.provider_type == "openai":
                with get_openai_callback() as cb:
                    response = await chain.ainvoke(chain_input)
                    self.cost_tracker.add_openai_callback_result(cb)
                    cost_usd = cb.total_cost
                    tokens_used = cb.total_tokens
            else:
                # ä»–ã®ãƒ—ãƒ­ãƒã‚¤ãƒ€ãƒ¼ã®å ´åˆï¼ˆæ¦‚ç®—ï¼‰
                response = await chain.ainvoke(chain_input)
                cost_usd = 0.0  # ãƒ—ãƒ­ãƒã‚¤ãƒ€ãƒ¼åˆ¥ã®ã‚³ã‚¹ãƒˆè¨ˆç®—ã‚’ã“ã“ã«è¿½åŠ 
                tokens_used = len(question) // 3 + len(response) // 3  # æ¦‚ç®—
                self.cost_tracker.add_manual_cost(cost_usd, tokens_used, self.provider_type)
            
            return {
                'success': True,
                'response': response,
                'cost_usd': cost_usd,
                'tokens_used': tokens_used,
                'provider': self.provider_type
            }
            
        except Exception as e:
            return {
                'success': False,
                'response': f"ã‚¨ãƒ©ãƒ¼: {str(e)[:50]}...",
                'cost_usd': 0.0,
                'tokens_used': 0,
                'provider': self.provider_type,
                'error': str(e)
            }

class AdvancedAnalysisChain:
    """é«˜åº¦ãªåˆ†æç”¨LangChainãƒã‚§ãƒ¼ãƒ³"""
    
    def __init__(self, llm_provider: LangChainLLMProvider):
        self.llm = llm_provider.llm
        self.setup_analysis_chains()
    
    def setup_analysis_chains(self):
        """åˆ†æç”¨ãƒã‚§ãƒ¼ãƒ³ã®è¨­å®š"""
        
        # æ´å¯Ÿç”Ÿæˆãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ
        self.insight_prompt = ChatPromptTemplate.from_messages([
            SystemMessagePromptTemplate.from_template(
                """ã‚ãªãŸã¯å°‚é–€çš„ãªèª¿æŸ»åˆ†æè€…ã§ã™ã€‚
ä»¥ä¸‹ã®èª¿æŸ»çµæœãƒ‡ãƒ¼ã‚¿ã‚’åˆ†æã—ã€ä¸»è¦ãªæ´å¯Ÿã¨æè¨€ã‚’ç”Ÿæˆã—ã¦ãã ã•ã„ã€‚
ãƒ‡ãƒ¼ã‚¿ã®å‚¾å‘ã€ãƒ‘ã‚¿ãƒ¼ãƒ³ã€æ„å‘³ã®ã‚ã‚‹ç™ºè¦‹ã‚’ç‰¹å®šã—ã€
å®Ÿç”¨çš„ãªæè¨€ã‚’å«ã‚ãŸåŒ…æ‹¬çš„ãªåˆ†æã‚’æä¾›ã—ã¦ãã ã•ã„ã€‚"""
            ),
            HumanMessagePromptTemplate.from_template(
                """èª¿æŸ»ãƒ‡ãƒ¼ã‚¿:
{survey_data}

è³ªå•: {question}

ä¸Šè¨˜ã®ãƒ‡ãƒ¼ã‚¿ã‹ã‚‰å¾—ã‚‰ã‚Œã‚‹ä¸»è¦ãªæ´å¯Ÿã¨æè¨€ã‚’ç”Ÿæˆã—ã¦ãã ã•ã„ã€‚"""
            )
        ])
        
        # æ´å¯Ÿç”Ÿæˆãƒã‚§ãƒ¼ãƒ³
        self.insight_chain = self.insight_prompt | self.llm | StrOutputParser()
    
    async def generate_insights(self, survey_data: str, question: str) -> str:
        """LLMã‚’ä½¿ç”¨ã—ãŸæ´å¯Ÿç”Ÿæˆ"""
        
        try:
            insights = await self.insight_chain.ainvoke({
                "survey_data": survey_data,
                "question": question
            })
            return insights
            
        except Exception as e:
            return f"æ´å¯Ÿç”Ÿæˆã‚¨ãƒ©ãƒ¼: {str(e)}"

class SimulationProvider:
    """ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ç”¨ãƒ—ãƒ­ãƒã‚¤ãƒ€ãƒ¼ï¼ˆLangChainæœªä½¿ç”¨æ™‚ï¼‰"""
    
    def __init__(self, mode: str):
        self.mode = mode
        self.cost_tracker = LangChainCostTracker()
        
        # å›ç­”ãƒ‘ã‚¿ãƒ¼ãƒ³ï¼ˆå‰å›ã¨åŒã˜ï¼‰
        self.human_response_patterns = {
            '25æ­³æœªæº€': [
                "å°†æ¥ä¸–ä»£ã«ã¨ã£ã¦æœ¬å½“ã«é‡è¦ãªå•é¡Œã ã¨æ€ã„ã¾ã™ã€‚",
                "SNSã§è¦‹ãŸæƒ…å ±ã ã¨ã€æ—©æ€¥ã«å¯¾ç­–ãŒå¿…è¦ãã†ã§ã™ã€‚",
                "ä»Šè¡Œå‹•ã—ãªã„ã¨æ‰‹é…ã‚Œã«ãªã‚Šãã†ã§å¿ƒé…ã§ã™ã€‚"
            ],
            '25-65æ­³': [
                "çµŒé¨“ä¸Šã€ãƒãƒ©ãƒ³ã‚¹ã®å–ã‚ŒãŸè§£æ±ºç­–ãŒå¿…è¦ã ã¨æ€ã„ã¾ã™ã€‚",
                "çµŒæ¸ˆçš„ãªå½±éŸ¿ã‚‚è€ƒæ…®ã—ã¤ã¤ã€ç’°å¢ƒå¯¾ç­–ã‚’é€²ã‚ã‚‹ã¹ãã§ã™ã€‚",
                "å®¶æ—ã®å°†æ¥ã‚’è€ƒãˆã‚‹ã¨ã€çœŸå‰£ã«å–ã‚Šçµ„ã‚€ã¹ãèª²é¡Œã§ã™ã€‚"
            ],
            '65æ­³ä»¥ä¸Š': [
                "é•·å¹´ã®å¤‰åŒ–ã‚’è¦‹ã¦ãã¦ã€ã“ã‚Œã¯é‡è¦ãªå•é¡Œã§ã™ã€‚",
                "å­«ã®ä¸–ä»£ã®ã“ã¨ã‚’è€ƒãˆã‚‹ã¨ã€å¯¾ç­–ãŒå¿…è¦ã§ã™ã€‚",
                "æŒç¶šå¯èƒ½ãªè§£æ±ºç­–ã‚’è¦‹ã¤ã‘ã‚‹ã“ã¨ãŒå¤§åˆ‡ã ã¨æ€ã„ã¾ã™ã€‚"
            ]
        }
        
        self.animal_response_patterns = {
            'è‚‰é£Ÿå‹•ç‰©': [
                "ç²ç‰©ã®æ•°ãŒå¤‰ã‚ã‚‹ã¨ã€ç‹©ã‚ŠãŒã‚‚ã£ã¨å¤§å¤‰ã«ãªã‚Šã¾ã™ã€‚",
                "ç”Ÿæ¯åœ°ã®åˆ†æ–­ã§ã€ç‹©ã‚Šã®ç¯„å›²ãŒç‹­ããªã£ã¦ã„ã¾ã™ã€‚",
                "æ°—å€™ã®å¤‰åŒ–ã§ã€ç²ç‰©ãŒã„ã‚‹å ´æ‰€ã‚„æ™‚æœŸãŒå¤‰ã‚ã£ã¦ãã¦ã„ã¾ã™ã€‚"
            ],
            'è‰é£Ÿå‹•ç‰©': [
                "æ¤ç‰©ã®ç”Ÿãˆã‚‹å ´æ‰€ã‚„æ™‚æœŸãŒå¤‰ã‚ã£ã¦ã€é£Ÿã¹ç‰©æ¢ã—ãŒé›£ã—ããªã£ã¦ã„ã¾ã™ã€‚",
                "å­£ç¯€ã®ãšã‚Œã§ã€å¥½ããªæ¤ç‰©ãŒé£Ÿã¹ã‚‰ã‚Œã‚‹æ™‚æœŸãŒå¤‰ã‚ã‚Šã¾ã—ãŸã€‚",
                "äººé–“ã®æ´»å‹•ã§ã€é£Ÿã¹ç‰©ã®ã‚ã‚‹å ´æ‰€ãŒæ¸›ã£ã¦ã„ã¾ã™ã€‚"
            ],
            'é›‘é£Ÿå‹•ç‰©': [
                "é£Ÿã¹ç‰©ã®ç¨®é¡ãŒå¤šã„ã®ã§é©å¿œã§ãã‚‹ã‘ã©ã€ã ã‚“ã ã‚“å³ã—ããªã£ã¦ã„ã¾ã™ã€‚",
                "æ¤ç‰©ã‚‚å‹•ç‰©ã‚‚é£Ÿã¹ã‚‰ã‚Œã‚‹ã‹ã‚‰ä½•ã¨ã‹ãªã‚‹ã‘ã©ã€ç’°å¢ƒã®å¤‰åŒ–ã¯æ„Ÿã˜ã¾ã™ã€‚",
                "æŸ”è»Ÿãªé£Ÿæ€§ãŒåŠ©ã‹ã‚‹ã‘ã©ã€ä½ã‚€å ´æ‰€ãŒãªããªã‚‹ã®ã¯å›°ã‚Šã¾ã™ã€‚"
            ]
        }
    
    async def generate_response(self, persona: Dict, question: str, mode: str) -> Dict:
        """ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³å›ç­”ç”Ÿæˆ"""
        await asyncio.sleep(0.1)
        
        if mode == "humans":
            age = persona.get('age', 30)
            if age < 25:
                age_group = '25æ­³æœªæº€'
            elif age <= 65:
                age_group = '25-65æ­³'
            else:
                age_group = '65æ­³ä»¥ä¸Š'
            
            responses = self.human_response_patterns[age_group]
            
        else:
            diet_type = persona.get('diet_type', 'é›‘é£Ÿå‹•ç‰©')
            responses = self.animal_response_patterns.get(diet_type, self.animal_response_patterns['é›‘é£Ÿå‹•ç‰©'])
        
        response = random.choice(responses)
        
        return {
            'success': True,
            'response': response,
            'cost_usd': 0.0,
            'tokens_used': 0,
            'provider': 'simulation'
        }

# ã‚¨ãƒ“ãƒ‡ãƒ³ã‚¹ãƒ™ãƒ¼ã‚¹è³ªå•ãƒ—ãƒªã‚»ãƒƒãƒˆ
EVIDENCE_BASED_QUESTIONS = {
    "æ°—å€™å¤‰å‹•ã®å½±éŸ¿": "æ°—å€™å¤‰å‹•ã¯ã‚ãªãŸã®ç’°å¢ƒã‚„æ—¥å¸¸ç”Ÿæ´»ã«ã©ã®ã‚ˆã†ãªå½±éŸ¿ã‚’ä¸ãˆã¦ã„ã¾ã™ã‹ï¼Ÿ",
    "ç”Ÿç‰©å¤šæ§˜æ€§ã®ä¿å…¨": "ç”Ÿç‰©å¤šæ§˜æ€§ã‚’å®ˆã‚‹ãŸã‚ã«æœ€ã‚‚é‡è¦ã ã¨æ€ã†å–ã‚Šçµ„ã¿ã¯ä½•ã§ã™ã‹ï¼Ÿ",
    "ç”Ÿæ¯åœ°ã®ä¿è­·": "ã‚ãªãŸã®åœ°åŸŸã§ã®ç”Ÿæ¯åœ°ä¿è­·ã¯ã©ã®ãã‚‰ã„é‡è¦ã§ã™ã‹ï¼Ÿ",
    "æŒç¶šå¯èƒ½ãªå®Ÿè·µ": "ã¿ã‚“ãªãŒå–ã‚Šçµ„ã‚€ã¹ãæŒç¶šå¯èƒ½ãªå®Ÿè·µã¯ä½•ã ã¨æ€ã„ã¾ã™ã‹ï¼Ÿ",
    "ç¨®ã®çµ¶æ»…ã¸ã®æ‡¸å¿µ": "ç¨®ã®çµ¶æ»…ã«ã¤ã„ã¦ã©ã®ãã‚‰ã„å¿ƒé…ã—ã¦ã„ã¾ã™ã‹ï¼Ÿ",
    "å†ç”Ÿå¯èƒ½ã‚¨ãƒãƒ«ã‚®ãƒ¼": "å°†æ¥ã€å†ç”Ÿå¯èƒ½ã‚¨ãƒãƒ«ã‚®ãƒ¼ã¯ã©ã®ã‚ˆã†ãªå½¹å‰²ã‚’æœãŸã™ã¹ãã§ã™ã‹ï¼Ÿ",
    "ãƒ—ãƒ©ã‚¹ãƒãƒƒã‚¯æ±šæŸ“": "ãƒ—ãƒ©ã‚¹ãƒãƒƒã‚¯æ±šæŸ“ã¯ã‚ãªãŸã®ç’°å¢ƒã«ã©ã®ã‚ˆã†ãªå½±éŸ¿ã‚’ä¸ãˆã¦ã„ã¾ã™ã‹ï¼Ÿ",
    "æ°´è³‡æºã®ä¿å…¨": "æœ€ã‚‚é‡è¦ãªæ°´è³‡æºä¿å…¨å¯¾ç­–ã¯ä½•ã ã¨æ€ã„ã¾ã™ã‹ï¼Ÿ",
    "æ£®æ—ç ´å£Šã¸ã®å¯¾ç­–": "æ£®æ—ç ´å£Šã‚’æ­¢ã‚ã‚‹ãŸã‚ã«ä½•ãŒå¿…è¦ã ã¨æ€ã„ã¾ã™ã‹ï¼Ÿ",
    "ç’°å¢ƒæ•™è‚²ã®é‡è¦æ€§": "ç’°å¢ƒæ•™è‚²ã¯ã©ã®ãã‚‰ã„é‡è¦ã ã¨æ€ã„ã¾ã™ã‹ï¼Ÿ"
}

# LLMãƒ—ãƒ­ãƒã‚¤ãƒ€ãƒ¼è¨­å®š
LLM_PROVIDERS = {
    "OpenAI GPT-4o-mini": {"type": "openai", "model": "gpt-4o-mini"},
    "OpenAI GPT-4": {"type": "openai", "model": "gpt-4"},
    "Anthropic Claude-3-Haiku": {"type": "anthropic", "model": "claude-3-haiku-20240307"},
    "Anthropic Claude-3-Sonnet": {"type": "anthropic", "model": "claude-3-sonnet-20240229"},
    "Google Gemini Pro": {"type": "google", "model": "gemini-pro"},
    "Ollama Llama2": {"type": "ollama", "model": "llama2"},
    "ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ï¼ˆç„¡æ–™ï¼‰": {"type": "simulation", "model": None}
}

# ã‚°ãƒ­ãƒ¼ãƒãƒ«çŠ¶æ…‹ç®¡ç†
class AppState:
    def __init__(self):
        self.mode = "humans"
        self.personas = []
        self.survey_responses = []
        self.llm_provider = None
        self.analysis_chain = None
        self.selected_provider = "ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ï¼ˆç„¡æ–™ï¼‰"

app_state = AppState()

# Gradioã‚¤ãƒ³ã‚¿ãƒ¼ãƒ•ã‚§ãƒ¼ã‚¹é–¢æ•°ç¾¤
def get_app_title():
    """ã‚¢ãƒ—ãƒªã‚¿ã‚¤ãƒˆãƒ«å–å¾—"""
    if app_state.mode == "humans":
        return "ğŸŒ World Listening (LangChainç‰ˆ)"
    else:
        return "ğŸ¦ Wild Listening (LangChainç‰ˆ)"

def set_mode(mode):
    """èª¿æŸ»ãƒ¢ãƒ¼ãƒ‰è¨­å®š"""
    app_state.mode = mode
    app_state.personas = []
    app_state.survey_responses = []
    return f"ãƒ¢ãƒ¼ãƒ‰è¨­å®š: {get_app_title()}"

def set_llm_provider(provider_name, api_key=""):
    """LLMãƒ—ãƒ­ãƒã‚¤ãƒ€ãƒ¼è¨­å®š"""
    app_state.selected_provider = provider_name
    provider_config = LLM_PROVIDERS[provider_name]
    
    if provider_config["type"] == "simulation":
        return "âœ… ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ãƒ¢ãƒ¼ãƒ‰ãŒæœ‰åŠ¹ã«ãªã‚Šã¾ã—ãŸï¼ˆç„¡æ–™ï¼‰"
    
    if not api_key:
        return f"âŒ {provider_name}ã‚’ä½¿ç”¨ã™ã‚‹ã«ã¯APIã‚­ãƒ¼ãŒå¿…è¦ã§ã™"
    
    try:
        app_state.llm_provider = LangChainLLMProvider(
            provider_type=provider_config["type"],
            api_key=api_key,
            model_name=provider_config["model"]
        )
        
        # é«˜åº¦åˆ†æãƒã‚§ãƒ¼ãƒ³ã®åˆæœŸåŒ–
        app_state.analysis_chain = AdvancedAnalysisChain(app_state.llm_provider)
        
        return f"âœ… {provider_name}ãƒ—ãƒ­ãƒã‚¤ãƒ€ãƒ¼ã®åˆæœŸåŒ–ãŒå®Œäº†ã—ã¾ã—ãŸï¼"
        
    except Exception as e:
        return f"âŒ {provider_name}ã®åˆæœŸåŒ–ã‚¨ãƒ©ãƒ¼: {e}"

def generate_personas(num_personas=50):
    """ãƒšãƒ«ã‚½ãƒŠç”Ÿæˆï¼ˆå‰å›ã¨åŒã˜ï¼‰"""
    try:
        generator = PersonaGenerator(app_state.mode)
        personas = []
        
        for i in range(num_personas):
            persona = generator.generate_persona(i + 1)
            personas.append(asdict(persona))
        
        app_state.personas = personas
        
        # ã‚µãƒãƒªãƒ¼ä½œæˆ
        df = pd.DataFrame(personas)
        if app_state.mode == "humans":
            summary = f"""
âœ… {len(personas)}äººã®äººé–“ãƒšãƒ«ã‚½ãƒŠã‚’ç”Ÿæˆã—ã¾ã—ãŸ:
- å¹³å‡å¹´é½¢: {df['age'].mean():.1f}æ­³
- æ€§åˆ¥åˆ†å¸ƒ: {df['gender'].value_counts().to_dict()}
- ä¸Šä½å›½å®¶: {df['country'].value_counts().head(3).to_dict()}
- è¨€èªæ•°: {len(df['language'].unique())}ç¨®é¡ã®è¨€èª
"""
        else:
            summary = f"""
âœ… {len(personas)}ä½“ã®å‹•ç‰©ãƒšãƒ«ã‚½ãƒŠã‚’ç”Ÿæˆã—ã¾ã—ãŸ:
- ç¨®æ•°: {len(df['species'].unique())}ç¨®é¡ã®å‹•ç‰©
- ç”Ÿæ¯ç’°å¢ƒåˆ†å¸ƒ: {df['habitat'].value_counts().head(3).to_dict()}
- é£Ÿæ€§åˆ†å¸ƒ: {df['diet_type'].value_counts().to_dict()}
- ä¿è­·çŠ¶æ³: {df['conservation_status'].value_counts().to_dict()}
"""
        
        return summary, create_persona_chart()
        
    except Exception as e:
        return f"âŒ ãƒšãƒ«ã‚½ãƒŠç”Ÿæˆã‚¨ãƒ©ãƒ¼: {e}", None

def create_persona_chart():
    """ãƒšãƒ«ã‚½ãƒŠåˆ†å¸ƒãƒãƒ£ãƒ¼ãƒˆä½œæˆï¼ˆå‰å›ã¨åŒã˜ï¼‰"""
    if not app_state.personas:
        return None
    
    df = pd.DataFrame(app_state.personas)
    
    if app_state.mode == "humans":
        fig = px.histogram(df, x='age', title='å¹´é½¢åˆ†å¸ƒ', nbins=20,
                          labels={'x': 'å¹´é½¢', 'y': 'äººæ•°'})
    else:
        species_counts = df['species'].value_counts().head(10)
        fig = px.bar(x=species_counts.values, y=species_counts.index, 
                    orientation='h', title='ä¸Šä½10ç¨®ã®åˆ†å¸ƒ',
                    labels={'x': 'å€‹ä½“æ•°', 'y': 'ç¨®å'})
    
    return fig

def run_survey(question, custom_question=""):
    """LangChainã‚’ä½¿ç”¨ã—ãŸèª¿æŸ»å®Ÿè¡Œ"""
    if not app_state.personas:
        return "âŒ ã¾ãšãƒšãƒ«ã‚½ãƒŠã‚’ç”Ÿæˆã—ã¦ãã ã•ã„", None, ""
    
    final_question = custom_question if custom_question.strip() else question
    if not final_question or final_question == "è³ªå•ã‚’é¸æŠã—ã¦ãã ã•ã„...":
        return "âŒ è³ªå•ã‚’é¸æŠã¾ãŸã¯å…¥åŠ›ã—ã¦ãã ã•ã„", None, ""
    
    try:
        # ãƒ—ãƒ­ãƒã‚¤ãƒ€ãƒ¼åˆæœŸåŒ–
        provider_config = LLM_PROVIDERS[app_state.selected_provider]
        
        if provider_config["type"] == "simulation":
            provider = SimulationProvider(app_state.mode)
        else:
            if not app_state.llm_provider:
                return "âŒ LLMãƒ—ãƒ­ãƒã‚¤ãƒ€ãƒ¼ãŒåˆæœŸåŒ–ã•ã‚Œã¦ã„ã¾ã›ã‚“", None, ""
            provider = app_state.llm_provider
        
        # èª¿æŸ»å®Ÿè¡Œ
        responses = []
        total_cost = 0
        
        async def run_async_survey():
            nonlocal responses, total_cost
            for persona in app_state.personas:
                result = await provider.generate_response(persona, final_question, app_state.mode)
                
                response = {
                    'persona_id': persona['id'],
                    'persona': persona,
                    'question': final_question,
                    'response': result['response'],
                    'success': result.get('success', True),
                    'cost_usd': result.get('cost_usd', 0.0),
                    'provider': result.get('provider', 'unknown'),
                    'timestamp': datetime.now().isoformat()
                }
                
                responses.append(response)
                total_cost += result.get('cost_usd', 0.0)
        
        # éåŒæœŸèª¿æŸ»å®Ÿè¡Œ
        asyncio.run(run_async_survey())
        
        app_state.survey_responses = responses
        
        # ã‚µãƒãƒªãƒ¼ä½œæˆ
        successful_responses = len([r for r in responses if r['success']])
        summary = f"""
âœ… èª¿æŸ»å®Œäº†ï¼
- è³ªå•: {final_question}
- ç·å›ç­”æ•°: {len(responses)}
- æˆåŠŸå›ç­”æ•°: {successful_responses}
- ç·ã‚³ã‚¹ãƒˆ: ${total_cost:.6f} (ç´„{total_cost * 150:.2f}å††)
- ãƒ—ãƒ­ãƒã‚¤ãƒ€ãƒ¼: {app_state.selected_provider}
"""
        
        return summary, create_results_chart(), get_sample_responses()
        
    except Exception as e:
        return f"âŒ èª¿æŸ»å®Ÿè¡Œã‚¨ãƒ©ãƒ¼: {e}", None, ""

def create_results_chart():
    """çµæœå¯è¦–åŒ–ä½œæˆï¼ˆå‰å›ã¨åŒã˜ï¼‰"""
    if not app_state.survey_responses:
        return None
    
    response_lengths = [len(r['response']) for r in app_state.survey_responses]
    
    fig = px.histogram(x=response_lengths, title='å›ç­”é•·åˆ†å¸ƒ', 
                      labels={'x': 'å›ç­”é•·ï¼ˆæ–‡å­—æ•°ï¼‰', 'y': 'å›ç­”æ•°'})
    
    return fig

def get_sample_responses():
    """ã‚µãƒ³ãƒ—ãƒ«å›ç­”å–å¾—ï¼ˆå‰å›ã¨åŒã˜ï¼‰"""
    if not app_state.survey_responses:
        return ""
    
    sample_size = min(5, len(app_state.survey_responses))
    sample_responses = random.sample(app_state.survey_responses, sample_size)
    
    output = "ğŸ“ å›ç­”ã‚µãƒ³ãƒ—ãƒ«:\n\n"
    
    for i, response in enumerate(sample_responses, 1):
        persona = response['persona']
        if app_state.mode == "humans":
            profile = f"{persona['country']}ã®{persona['age']}æ­³{persona['gender']}"
        else:
            profile = f"{persona['habitat']}ã®{persona['species']}"
        
        output += f"{i}. **{profile}**\n"
        output += f"ğŸ’¬ {response['response']}\n\n"
    
    return output

def generate_ai_insights():
    """AIæ´å¯Ÿç”Ÿæˆï¼ˆLangChainä½¿ç”¨ï¼‰"""
    if not app_state.survey_responses:
        return "âŒ ã¾ãšèª¿æŸ»ã‚’å®Ÿè¡Œã—ã¦ãã ã•ã„"
    
    if not app_state.analysis_chain:
        return "âŒ åˆ†æç”¨LLMãŒåˆæœŸåŒ–ã•ã‚Œã¦ã„ã¾ã›ã‚“"
    
    try:
        # èª¿æŸ»ãƒ‡ãƒ¼ã‚¿ã®æº–å‚™
        survey_data = ""
        for response in app_state.survey_responses[:10]:  # ã‚µãƒ³ãƒ—ãƒ«10ä»¶
            persona = response['persona']
            if app_state.mode == "humans":
                profile = f"{persona['country']}ã®{persona['age']}æ­³{persona['gender']}"
            else:
                profile = f"{persona['habitat']}ã®{persona['species']}"
            
            survey_data += f"- {profile}: {response['response']}\n"
        
        question = app_state.survey_responses[0]['question']
        
        # éåŒæœŸã§æ´å¯Ÿç”Ÿæˆ
        async def generate_async():
            return await app_state.analysis_chain.generate_insights(survey_data, question)
        
        insights = asyncio.run(generate_async())
        return f"ğŸ¤– AIç”Ÿæˆæ´å¯Ÿ:\n\n{insights}"
        
    except Exception as e:
        return f"âŒ AIæ´å¯Ÿç”Ÿæˆã‚¨ãƒ©ãƒ¼: {e}"

def export_results():
    """çµæœCSVå‡ºåŠ›ï¼ˆå‰å›ã¨åŒã˜ï¼‰"""
    if not app_state.survey_responses:
        return None
    
    export_data = []
    for response in app_state.survey_responses:
        row = {
            'persona_id': response['persona_id'],
            'question': response['question'],
            'response': response['response'],
            'success': response['success'],
            'provider': response.get('provider', 'unknown'),
            'timestamp': response['timestamp']
        }
        
        persona = response['persona']
        for key, value in persona.items():
            row[f'persona_{key}'] = value
        
        export_data.append(row)
    
    df = pd.DataFrame(export_data)
    
    filename = f"langchain_survey_export_{datetime.now().strftime('%Y%m%d_%H%M%S')}.csv"
    df.to_csv(filename, index=False, encoding='utf-8-sig')
    
    return filename

# Gradioã‚¤ãƒ³ã‚¿ãƒ¼ãƒ•ã‚§ãƒ¼ã‚¹ä½œæˆ
def create_interface():
    """LangChainç‰ˆGradioã‚¤ãƒ³ã‚¿ãƒ¼ãƒ•ã‚§ãƒ¼ã‚¹ä½œæˆ"""
    
    with gr.Blocks(title="World & Wild Listening - LangChainç‰ˆ", theme=gr.themes.Soft()) as demo:
        
        # å‹•çš„ã‚¿ã‚¤ãƒˆãƒ«
        title_display = gr.Markdown("# ğŸŒ World Listening (LangChainç‰ˆ)")
        
        gr.Markdown("""
        ### ğŸš€ LangChainæ­è¼‰ - ãƒãƒ«ãƒLLMå¯¾å¿œä¸–ç•Œè¦æ¨¡èª¿æŸ»ã‚·ã‚¹ãƒ†ãƒ 
        
        **æ–°æ©Ÿèƒ½:**
        - ğŸ”„ è¤‡æ•°LLMãƒ—ãƒ­ãƒã‚¤ãƒ€ãƒ¼å¯¾å¿œï¼ˆOpenAIã€Anthropicã€Googleã€Ollamaï¼‰
        - ğŸ§  AIæ´å¯Ÿè‡ªå‹•ç”Ÿæˆ
        - ğŸ“Š é«˜åº¦ãªçµ±è¨ˆåˆ†æ
        - ğŸ’° ãƒ—ãƒ­ãƒã‚¤ãƒ€ãƒ¼åˆ¥ã‚³ã‚¹ãƒˆæœ€é©åŒ–
        """)
        
        with gr.Tabs():
            # è¨­å®šã‚¿ãƒ–
            with gr.Tab("âš™ï¸ è¨­å®š"):
                gr.Markdown("### èª¿æŸ»å¯¾è±¡é¸æŠ")
                
                mode_radio = gr.Radio(
                    choices=[("äººé–“ï¼ˆä¸–ç•Œï¼‰", "humans"), ("å‹•ç‰©ï¼ˆé™¸ä¸Šï¼‰", "animals")],
                    value="humans",
                    label="èª¿æŸ»å¯¾è±¡",
                    info="äººé–“ãƒšãƒ«ã‚½ãƒŠã¾ãŸã¯å‹•ç‰©ãƒšãƒ«ã‚½ãƒŠã®ã©ã¡ã‚‰ã‚’èª¿æŸ»ã™ã‚‹ã‹ã‚’é¸æŠ"
                )
                
                mode_status = gr.Textbox(label="ãƒ¢ãƒ¼ãƒ‰çŠ¶æ³", value="ãƒ¢ãƒ¼ãƒ‰: ğŸŒ World Listening (LangChainç‰ˆ)")
                
                gr.Markdown("### ğŸ¤– LLMãƒ—ãƒ­ãƒã‚¤ãƒ€ãƒ¼é¸æŠ")
                
                provider_dropdown = gr.Dropdown(
                    choices=list(LLM_PROVIDERS.keys()),
                    value="ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ï¼ˆç„¡æ–™ï¼‰",
                    label="LLMãƒ—ãƒ­ãƒã‚¤ãƒ€ãƒ¼",
                    info="ä½¿ç”¨ã™ã‚‹LLMãƒ—ãƒ­ãƒã‚¤ãƒ€ãƒ¼ã‚’é¸æŠ"
                )
                
                api_key_input = gr.Textbox(
                    label="APIã‚­ãƒ¼",
                    type="password",
                    placeholder="ãƒ—ãƒ­ãƒã‚¤ãƒ€ãƒ¼ã®APIã‚­ãƒ¼ã‚’å…¥åŠ›...",
                    info="ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ä»¥å¤–ã‚’é¸æŠã—ãŸå ´åˆã«å¿…è¦"
                )
                
                llm_status = gr.Textbox(label="LLMçŠ¶æ³", value="ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ãƒ¢ãƒ¼ãƒ‰ï¼ˆç„¡æ–™ï¼‰")
                
                # ã‚¤ãƒ™ãƒ³ãƒˆãƒãƒ³ãƒ‰ãƒ©ãƒ¼
                def update_title_and_mode(mode):
                    app_state.mode = mode
                    if mode == "humans":
                        title = "# ğŸŒ World Listening (LangChainç‰ˆ)"
                        status = "ãƒ¢ãƒ¼ãƒ‰: ğŸŒ World Listening (LangChainç‰ˆ)"
                    else:
                        title = "# ğŸ¦ Wild Listening (LangChainç‰ˆ)"
                        status = "ãƒ¢ãƒ¼ãƒ‰: ğŸ¦ Wild Listening (LangChainç‰ˆ)"
                    return title, status
                
                mode_radio.change(
                    fn=update_title_and_mode,
                    inputs=[mode_radio],
                    outputs=[title_display, mode_status]
                )
                
                provider_dropdown.change(
                    fn=set_llm_provider,
                    inputs=[provider_dropdown, api_key_input],
                    outputs=[llm_status]
                )
                
                api_key_input.change(
                    fn=set_llm_provider,
                    inputs=[provider_dropdown, api_key_input],
                    outputs=[llm_status]
                )
            
            # ãƒšãƒ«ã‚½ãƒŠç”Ÿæˆã‚¿ãƒ–
            with gr.Tab("ğŸ‘¥ ãƒšãƒ«ã‚½ãƒŠ"):
                gr.Markdown("### èª¿æŸ»ãƒšãƒ«ã‚½ãƒŠç”Ÿæˆ")
                
                num_personas = gr.Slider(
                    minimum=10,
                    maximum=200,
                    value=50,
                    step=10,
                    label="ãƒšãƒ«ã‚½ãƒŠæ•°",
                    info="å¤šã„ã»ã©åŒ…æ‹¬çš„ãªèª¿æŸ»ï¼ˆå®ŸLLMä½¿ç”¨æ™‚ã¯ã‚³ã‚¹ãƒˆå¢—ï¼‰"
                )
                
                generate_btn = gr.Button("ğŸ² ãƒšãƒ«ã‚½ãƒŠç”Ÿæˆ", variant="primary")
                
                persona_status = gr.Textbox(label="ç”ŸæˆçŠ¶æ³")
                persona_chart = gr.Plot(label="ãƒšãƒ«ã‚½ãƒŠåˆ†å¸ƒ")
                
                generate_btn.click(
                    fn=generate_personas,
                    inputs=[num_personas],
                    outputs=[persona_status, persona_chart]
                )
            
            # èª¿æŸ»ã‚¿ãƒ–
            with gr.Tab("â“ èª¿æŸ»"):
                gr.Markdown("### ğŸŒ± ã‚¨ãƒ“ãƒ‡ãƒ³ã‚¹ãƒ™ãƒ¼ã‚¹èª¿æŸ»å®Ÿè¡Œ")
                
                question_dropdown = gr.Dropdown(
                    choices=["è³ªå•ã‚’é¸æŠã—ã¦ãã ã•ã„..."] + list(EVIDENCE_BASED_QUESTIONS.keys()),
                    value="è³ªå•ã‚’é¸æŠã—ã¦ãã ã•ã„...",
                    label="ãƒ—ãƒªã‚»ãƒƒãƒˆè³ªå•",
                    info="ç’°å¢ƒãƒ»ä¿å…¨ãƒ»æŒç¶šå¯èƒ½æ€§ã«é–¢ã™ã‚‹ã‚¨ãƒ“ãƒ‡ãƒ³ã‚¹ãƒ™ãƒ¼ã‚¹ã®ãƒˆãƒ”ãƒƒã‚¯"
                )
                
                custom_question = gr.Textbox(
                    label="ã‚«ã‚¹ã‚¿ãƒ è³ªå•",
                    placeholder="ã¾ãŸã¯ç‹¬è‡ªã®è³ªå•ã‚’å…¥åŠ›...",
                    lines=3,
                    info="ãƒ—ãƒªã‚»ãƒƒãƒˆè³ªå•ä½¿ç”¨æ™‚ã¯ç©ºã®ã¾ã¾ã§"
                )
                
                def update_custom_question(selected):
                    if selected and selected != "è³ªå•ã‚’é¸æŠã—ã¦ãã ã•ã„...":
                        return EVIDENCE_BASED_QUESTIONS[selected]
                    return ""
                
                question_dropdown.change(
                    fn=update_custom_question,
                    inputs=[question_dropdown],
                    outputs=[custom_question]
                )
                
                run_survey_btn = gr.Button("ğŸš€ èª¿æŸ»å®Ÿè¡Œ", variant="primary")
                
                survey_status = gr.Textbox(label="èª¿æŸ»çŠ¶æ³")
                results_chart = gr.Plot(label="çµæœå¯è¦–åŒ–")
                sample_responses = gr.Textbox(
                    label="ã‚µãƒ³ãƒ—ãƒ«å›ç­”",
                    lines=10,
                    max_lines=20
                )
                
                run_survey_btn.click(
                    fn=run_survey,
                    inputs=[question_dropdown, custom_question],
                    outputs=[survey_status, results_chart, sample_responses]
                )
            
            # AIæ´å¯Ÿã‚¿ãƒ–
            with gr.Tab("ğŸ§  AIæ´å¯Ÿ"):
                gr.Markdown("### ğŸ¤– LangChainã«ã‚ˆã‚‹é«˜åº¦ãªåˆ†æ")
                
                gr.Markdown("""
                **æ©Ÿèƒ½:**
                - èª¿æŸ»çµæœã®è‡ªå‹•åˆ†æ
                - ãƒ‘ã‚¿ãƒ¼ãƒ³èªè­˜ã¨æ´å¯Ÿç”Ÿæˆ
                - å®Ÿç”¨çš„ãªæè¨€ã®ç”Ÿæˆ
                - å¤šè§’çš„è¦–ç‚¹ã§ã®è§£é‡ˆ
                """)
                
                generate_insights_btn = gr.Button("ğŸ§  AIæ´å¯Ÿç”Ÿæˆ", variant="primary")
                
                ai_insights = gr.Textbox(
                    label="AIç”Ÿæˆæ´å¯Ÿ",
                    lines=15,
                    max_lines=30
                )
                
                generate_insights_btn.click(
                    fn=generate_ai_insights,
                    outputs=[ai_insights]
                )
            
            # ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆã‚¿ãƒ–
            with gr.Tab("ğŸ“¤ ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆ"):
                gr.Markdown("### çµæœå‡ºåŠ›")
                
                export_btn = gr.Button("ğŸ“Š CSVã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆ", variant="secondary")
                export_file = gr.File(label="çµæœãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰")
                
                export_btn.click(
                    fn=export_results,
                    outputs=[export_file]
                )
                
                gr.Markdown("""
                ### ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆå†…å®¹
                CSVãƒ•ã‚¡ã‚¤ãƒ«ã«ã¯ä»¥ä¸‹ãŒå«ã¾ã‚Œã¾ã™ï¼š
                - å…¨èª¿æŸ»å›ç­”
                - å®Œå…¨ãªãƒšãƒ«ã‚½ãƒŠãƒ—ãƒ­ãƒ•ã‚¡ã‚¤ãƒ«
                - ä½¿ç”¨ãƒ—ãƒ­ãƒã‚¤ãƒ€ãƒ¼æƒ…å ±
                - ã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—ã¨ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿
                - æˆåŠŸãƒ»å¤±æ•—ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹
                """)
        
        # ãƒ•ãƒƒã‚¿ãƒ¼
        gr.Markdown("""
        ---
        **ğŸš€ Powered by LangChain** | ãƒãƒ«ãƒLLMå¯¾å¿œãƒ»ã‚³ã‚¹ãƒˆæœ€é©åŒ–
        
        **å¯¾å¿œãƒ—ãƒ­ãƒã‚¤ãƒ€ãƒ¼:**
        - ğŸ”µ OpenAI (GPT-4o-mini, GPT-4)
        - ğŸŸ£ Anthropic (Claude-3-Haiku, Claude-3-Sonnet)
        - ğŸ”´ Google (Gemini Pro)
        - ğŸŸ¢ Ollama (Llama2, ãã®ä»–ãƒ­ãƒ¼ã‚«ãƒ«ãƒ¢ãƒ‡ãƒ«)
        
        **ã‚¨ãƒ“ãƒ‡ãƒ³ã‚¹ãƒ™ãƒ¼ã‚¹ãƒˆãƒ”ãƒƒã‚¯:**
        - æ°—å€™å¤‰å‹•ã¨ç’°å¢ƒå½±éŸ¿
        - ç”Ÿç‰©å¤šæ§˜æ€§ã¨ä¿å…¨
        - æŒç¶šå¯èƒ½ãªå®Ÿè·µ
        - ç’°å¢ƒæ•™è‚²
        """)
    
    return demo

if __name__ == "__main__":
    demo = create_interface()
    demo.launch(
        server_name="0.0.0.0",
        server_port=7860,
        share=False,
        show_error=True
    )